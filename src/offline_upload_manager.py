import os
import sqlite3
import threading
import time
import json
from datetime import datetime, timezone, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from system_logger import log_info, log_success, log_warning, log_error, log_debug
from network_checker import NetworkConnectivityChecker
from supabase_manager import SupabaseManager
from replay_manager import ReplayManager


class OfflineUploadManager:
    """
    Gerencia uploads autom√°ticos de v√≠deos quando a conectividade √© restaurada.
    Monitora continuamente a conectividade e processa fila de uploads pendentes.
    """
    
    def __init__(self, db_path: str = None, config_env_path: str = None):
        # Garantir que offline_data seja criado na raiz do projeto
        if db_path is None:
            from pathlib import Path
            project_root = Path(__file__).parent.parent
            offline_data_dir = project_root / "offline_data"
            offline_data_dir.mkdir(exist_ok=True)
            self.db_path = str(offline_data_dir / "upload_queue.db")
        else:
            self.db_path = db_path
            
        self.config_env_path = config_env_path or os.path.join(os.getcwd(), 'config.env')
        
        # Configura√ß√µes padr√£o
        self.max_retry_attempts = int(os.getenv('OFFLINE_MAX_RETRY_ATTEMPTS', '5'))
        self.retry_delay_base = int(os.getenv('OFFLINE_RETRY_DELAY_BASE', '60'))  # segundos
        self.connectivity_check_interval = int(os.getenv('OFFLINE_CONNECTIVITY_CHECK_INTERVAL', '30'))  # segundos
        self.upload_batch_size = int(os.getenv('OFFLINE_UPLOAD_BATCH_SIZE', '3'))
        self.max_queue_size = int(os.getenv('OFFLINE_MAX_QUEUE_SIZE', '1000'))
        self.expiration_hours = int(os.getenv('OFFLINE_EXPIRATION_HOURS', '168'))  # 7 dias
        
        # Componentes
        self.network_checker = NetworkConnectivityChecker()
        self.supabase_manager = None
        self.replay_manager = None
        
        # Threading
        self._running = False
        self._monitor_thread = None
        self._upload_lock = threading.Lock()
        
        # Estat√≠sticas
        self.stats = {
            'total_processed': 0,
            'successful_uploads': 0,
            'failed_uploads': 0,
            'last_cleanup': None,
            'last_connectivity_check': None
        }
        
        self._initialize_database()
        self._load_supabase_manager()
        self._initialize_replay_manager()
        
    def _load_supabase_manager(self):
        """Carrega o SupabaseManager com configura√ß√µes do ambiente."""
        try:
            self.supabase_manager = SupabaseManager()
            log_success("‚úÖ SupabaseManager carregado com sucesso")
        except Exception as e:
            log_error(f"‚ùå Erro ao carregar SupabaseManager: {e}")
            self.supabase_manager = None
    
    def _initialize_replay_manager(self):
        """Inicializa ReplayManager ap√≥s SupabaseManager."""
        try:
            if self.supabase_manager and self.supabase_manager.supabase:
                self.replay_manager = ReplayManager(supabase_manager=self.supabase_manager)
                log_success("‚úÖ ReplayManager inicializado no OfflineUploadManager")
            else:
                log_warning("‚ö†Ô∏è SupabaseManager n√£o dispon√≠vel para ReplayManager")
        except Exception as e:
            log_error(f"‚ùå Erro ao inicializar ReplayManager: {e}")
    
    def _initialize_database(self):
        """Inicializa o banco de dados SQLite para a fila de uploads."""
        try:
            os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Tabela principal de fila de uploads
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS upload_queue (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        video_path TEXT NOT NULL,
                        camera_id TEXT NOT NULL,
                        session_id TEXT,
                        timestamp_created TEXT NOT NULL,
                        file_size INTEGER,
                        checksum TEXT,
                        priority INTEGER DEFAULT 1,
                        status TEXT DEFAULT 'pending',
                        retry_count INTEGER DEFAULT 0,
                        last_attempt TEXT,
                        error_message TEXT,
                        supabase_url TEXT,
                        bucket_path TEXT,
                        arena TEXT,
                        quadra TEXT
                    )
                ''')
                
                # Tabela de configura√ß√µes
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS upload_config (
                        key TEXT PRIMARY KEY,
                        value TEXT NOT NULL,
                        updated_at TEXT NOT NULL
                    )
                ''')
                
                # Tabela de log de conectividade
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS connectivity_log (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TEXT NOT NULL,
                        status TEXT NOT NULL,
                        latency REAL,
                        error_details TEXT
                    )
                ''')
                
                conn.commit()
                
                # Executa migra√ß√µes se necess√°rio
                self._run_migrations(conn)
                
                log_success("‚úÖ Banco de dados inicializado com sucesso")
                
        except Exception as e:
            log_error(f"‚ùå Erro ao inicializar banco de dados: {e}")
            raise
    
    def _run_migrations(self, conn):
        """Executa migra√ß√µes necess√°rias no banco de dados."""
        try:
            cursor = conn.cursor()
            
            # Verifica se as colunas arena e quadra existem
            cursor.execute("PRAGMA table_info(upload_queue)")
            columns = cursor.fetchall()
            column_names = [col[1] for col in columns]
            
            # NOVA MIGRA√á√ÉO: Tornar checksum opcional
            # Verificar se checksum √© NOT NULL
            checksum_info = next((col for col in columns if col[1] == 'checksum'), None)
            if checksum_info and checksum_info[3] == 1:  # notNull = 1
                log_info("üîÑ Migra√ß√£o: Tornando checksum opcional")
                # Criar nova tabela sem NOT NULL no checksum
                cursor.execute('''
                    CREATE TABLE upload_queue_new (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        video_path TEXT NOT NULL,
                        camera_id TEXT NOT NULL,
                        session_id TEXT,
                        timestamp_created TEXT NOT NULL,
                        file_size INTEGER,
                        checksum TEXT,  -- SEM NOT NULL
                        priority INTEGER DEFAULT 1,
                        status TEXT DEFAULT 'pending',
                        retry_count INTEGER DEFAULT 0,
                        last_attempt TEXT,
                        error_message TEXT,
                        supabase_url TEXT,
                        bucket_path TEXT,
                        arena TEXT,
                        quadra TEXT
                    )
                ''')
                
                # Copiar dados existentes
                cursor.execute('''
                    INSERT INTO upload_queue_new 
                    SELECT * FROM upload_queue
                ''')
                
                # Substituir tabela antiga
                cursor.execute('DROP TABLE upload_queue')
                cursor.execute('ALTER TABLE upload_queue_new RENAME TO upload_queue')
                
                log_success("‚úÖ Migra√ß√£o conclu√≠da: checksum agora √© opcional")
            
            # Adiciona coluna 'arena' se n√£o existir
            if 'arena' not in column_names:
                log_info("üîÑ Migra√ß√£o: Adicionando coluna 'arena'")
                cursor.execute("ALTER TABLE upload_queue ADD COLUMN arena TEXT")
                
            # Adiciona coluna 'quadra' se n√£o existir
            if 'quadra' not in column_names:
                log_info("üîÑ Migra√ß√£o: Adicionando coluna 'quadra'")
                cursor.execute("ALTER TABLE upload_queue ADD COLUMN quadra TEXT")
            
            # NOVA MIGRA√á√ÉO: Campos para registro replay
            if 'timestamp_video' not in column_names:
                log_info("üîÑ Migra√ß√£o: Adicionando coluna 'timestamp_video'")
                cursor.execute("ALTER TABLE upload_queue ADD COLUMN timestamp_video TEXT")
            
            if 'camera_uuid' not in column_names:
                log_info("üîÑ Migra√ß√£o: Adicionando coluna 'camera_uuid'")
                cursor.execute("ALTER TABLE upload_queue ADD COLUMN camera_uuid TEXT")
            
            if 'replay_inserted' not in column_names:
                log_info("üîÑ Migra√ß√£o: Adicionando coluna 'replay_inserted'")
                cursor.execute("ALTER TABLE upload_queue ADD COLUMN replay_inserted INTEGER DEFAULT 0")
                
            conn.commit()
            
        except Exception as e:
            log_warning(f"‚ö†Ô∏è Erro durante migra√ß√µes: {e}")
    
    def add_to_queue(self, video_path: str, camera_id: str, bucket_path: str, 
                     session_id: str = None, arena: str = None, quadra: str = None,
                     priority: int = 1, timestamp_video: str = None, 
                     camera_uuid: str = None) -> bool:
        """Adiciona um v√≠deo √† fila de upload offline."""
        try:
            if not os.path.exists(video_path):
                log_error(f"‚ùå Arquivo n√£o encontrado: {video_path}")
                return False
            
            file_size = os.path.getsize(video_path)
            timestamp_created = datetime.now(timezone.utc).isoformat()
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Verifica se j√° existe na fila
                cursor.execute(
                    "SELECT id FROM upload_queue WHERE video_path = ? AND status = 'pending'",
                    (video_path,)
                )
                
                if cursor.fetchone():
                    log_warning(f"‚ö†Ô∏è V√≠deo j√° est√° na fila: {os.path.basename(video_path)}")
                    return True
                
                # Adiciona √† fila
                cursor.execute('''
                    INSERT INTO upload_queue 
                    (video_path, camera_id, session_id, timestamp_created, file_size, 
                     bucket_path, arena, quadra, priority, status, timestamp_video, 
                     camera_uuid, replay_inserted)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, 'pending', ?, ?, 0)
                ''', (video_path, camera_id, session_id, timestamp_created, file_size,
                      bucket_path, arena, quadra, priority, timestamp_video, camera_uuid))
                
                conn.commit()
                
            log_success(f"‚úÖ V√≠deo adicionado √† fila offline: {os.path.basename(video_path)}")
            return True
            
        except Exception as e:
            log_error(f"‚ùå Erro ao adicionar v√≠deo √† fila: {e}")
            return False
    
    def start_monitoring(self):
        """Inicia o monitoramento cont√≠nuo de conectividade e processamento da fila."""
        if self._running:
            log_warning("‚ö†Ô∏è Monitoramento j√° est√° em execu√ß√£o")
            return
        
        self._running = True
        self._monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self._monitor_thread.start()
        
        log_info("üîÑ Monitoramento de upload offline iniciado")
    
    def stop_monitoring(self):
        """Para o monitoramento de conectividade."""
        self._running = False
        
        if self._monitor_thread and self._monitor_thread.is_alive():
            self._monitor_thread.join(timeout=5)
        
        log_info("‚èπÔ∏è Monitoramento de upload offline parado")
    
    def _monitor_loop(self):
        """Loop principal de monitoramento."""
        log_info("üîÑ Iniciando loop de monitoramento offline")
        
        while self._running:
            try:
                # Verifica conectividade
                is_connected = self._check_connectivity()
                
                if is_connected:
                    # Processa fila de uploads
                    self._process_upload_queue()
                    
                    # Limpeza peri√≥dica
                    self._cleanup_old_entries()
                
                # Aguarda pr√≥xima verifica√ß√£o
                time.sleep(self.connectivity_check_interval)
                
            except Exception as e:
                log_error(f"‚ùå Erro no loop de monitoramento: {e}")
                time.sleep(self.connectivity_check_interval)
    
    def _check_connectivity(self) -> Dict:
        """Verifica conectividade com internet e Supabase."""
        try:
            connectivity_result = self.network_checker.check_full_connectivity()
            
            # Log da conectividade
            self._log_connectivity(connectivity_result)
            
            self.stats['last_connectivity_check'] = datetime.now(timezone.utc).isoformat()
            
            return {
                'internet': connectivity_result.get('internet_accessible', False),
                'supabase': connectivity_result.get('supabase_accessible', False)
            }
            
        except Exception as e:
            log_error(f"‚ùå Erro ao verificar conectividade: {e}")
            return {'internet': False, 'supabase': False}
    
    def _log_connectivity(self, connectivity_result: Dict):
        """Registra status de conectividade no banco."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                status = 'online' if connectivity_result.get('supabase_accessible') else 'offline'
                error_details = connectivity_result.get('error', '')
                
                # Inserir apenas com colunas b√°sicas para evitar problemas de schema
                cursor.execute('''
                    INSERT INTO connectivity_log (timestamp, status, error_details)
                    VALUES (?, ?, ?)
                ''', (datetime.now(timezone.utc).isoformat(), status, error_details))
                
                conn.commit()
                
        except Exception as e:
            log_error(f"‚ùå Erro ao registrar conectividade: {e}")
    
    def _process_upload_queue(self):
        """Processa a fila de uploads pendentes."""
        with self._upload_lock:
            try:
                pending_uploads = self._get_pending_uploads()
                
                if not pending_uploads:
                    return
                
                log_info(f"üîÑ Processando {len(pending_uploads)} uploads pendentes")
                
                # Processa uploads em paralelo
                with ThreadPoolExecutor(max_workers=self.upload_batch_size) as executor:
                    future_to_upload = {
                        executor.submit(self._process_single_upload, upload): upload
                        for upload in pending_uploads[:self.upload_batch_size]
                    }
                    
                    for future in as_completed(future_to_upload):
                        upload = future_to_upload[future]
                        try:
                            success = future.result()
                            if success:
                                self.stats['successful_uploads'] += 1
                            else:
                                self.stats['failed_uploads'] += 1
                                
                        except Exception as e:
                            log_error(f"‚ùå Erro no upload de {upload['video_path']}: {e}")
                            self.stats['failed_uploads'] += 1
                
                self.stats['total_processed'] += len(pending_uploads[:self.upload_batch_size])
                
            except Exception as e:
                log_error(f"‚ùå Erro ao processar fila de uploads: {e}")
    
    def _get_pending_uploads(self) -> List[Dict]:
        """Obt√©m uploads pendentes da fila, ordenados por prioridade e data."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute('''
                    SELECT id, video_path, camera_id, session_id, bucket_path, 
                           arena, quadra, retry_count, priority, timestamp_video, 
                           camera_uuid, replay_inserted
                    FROM upload_queue 
                    WHERE status = 'pending' AND retry_count < ?
                    ORDER BY priority DESC, timestamp_created ASC
                    LIMIT ?
                ''', (self.max_retry_attempts, self.upload_batch_size * 2))
                
                columns = [desc[0] for desc in cursor.description]
                return [dict(zip(columns, row)) for row in cursor.fetchall()]
                
        except Exception as e:
            log_error(f"‚ùå Erro ao obter uploads pendentes: {e}")
            return []
    
    def _process_single_upload(self, upload: Dict) -> bool:
        """Processa um √∫nico upload."""
        video_path = upload['video_path']
        upload_id = upload['id']
        
        try:
            # Verifica se arquivo ainda existe
            if not os.path.exists(video_path):
                self._update_upload_status(upload_id, 'failed', 'Arquivo n√£o encontrado')
                log_warning(f"‚ö†Ô∏è Arquivo n√£o encontrado: {video_path}")
                return False
            
            # Atualiza tentativa
            self._update_upload_attempt(upload_id)
            
            # Realiza upload
            if not self.supabase_manager:
                raise Exception("SupabaseManager n√£o dispon√≠vel")
            
            upload_result = self.supabase_manager.upload_video_to_bucket(
                video_path, upload['bucket_path']
            )
            
            if upload_result and upload_result.get('success'):
                # Upload bem-sucedido
                self._update_upload_status(upload_id, 'completed', None, upload_result.get('url'))
                
                # Inserir registro replay se necess√°rio
                if upload.get('replay_inserted', 0) == 0 and upload.get('timestamp_video') and upload.get('camera_uuid'):
                    success_replay = self._insert_replay_record(upload, upload_result.get('url'))
                    if success_replay:
                        self._mark_replay_inserted(upload_id)
                
                # Remove arquivo local se configurado
                if os.getenv('OFFLINE_DELETE_AFTER_UPLOAD', 'true').lower() == 'true':
                    try:
                        os.remove(video_path)
                        log_debug(f"üóëÔ∏è Arquivo local removido: {os.path.basename(video_path)}")
                    except Exception as e:
                        log_warning(f"‚ö†Ô∏è Erro ao remover arquivo local: {e}")
                
                log_success(f"‚úÖ Upload conclu√≠do: {os.path.basename(video_path)}")
                return True
            else:
                # Upload falhou
                error_msg = upload_result.get('error', 'Erro desconhecido') if upload_result else 'Upload falhou'
                self._update_upload_status(upload_id, 'pending', error_msg)
                log_error(f"‚ùå Falha no upload: {os.path.basename(video_path)} - {error_msg}")
                return False
                
        except Exception as e:
            error_msg = str(e)
            self._update_upload_status(upload_id, 'pending', error_msg)
            log_error(f"‚ùå Erro no upload de {os.path.basename(video_path)}: {error_msg}")
            return False
    
    def _update_upload_attempt(self, upload_id: int):
        """Atualiza contador de tentativas de upload."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute('''
                    UPDATE upload_queue 
                    SET retry_count = retry_count + 1, last_attempt = ?
                    WHERE id = ?
                ''', (datetime.now(timezone.utc).isoformat(), upload_id))
                
                conn.commit()
                
        except Exception as e:
            log_error(f"‚ùå Erro ao atualizar tentativa de upload: {e}")
    
    def _update_upload_status(self, upload_id: int, status: str, error_message: str = None, 
                             supabase_url: str = None):
        """Atualiza status de um upload na fila."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute('''
                    UPDATE upload_queue 
                    SET status = ?, error_message = ?, supabase_url = ?, last_attempt = ?
                    WHERE id = ?
                ''', (status, error_message, supabase_url, 
                      datetime.now(timezone.utc).isoformat(), upload_id))
                
                conn.commit()
                
        except Exception as e:
            log_error(f"‚ùå Erro ao atualizar status de upload: {e}")
    
    def _cleanup_old_entries(self):
        """Remove entradas antigas e conclu√≠das da fila."""
        try:
            # Verifica se precisa fazer limpeza
            last_cleanup = self.stats.get('last_cleanup')
            if last_cleanup:
                last_cleanup_dt = datetime.fromisoformat(last_cleanup.replace('Z', '+00:00'))
                if datetime.now(timezone.utc) - last_cleanup_dt < timedelta(hours=24):
                    return
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Remove uploads conclu√≠dos h√° mais de X horas
                expiration_time = datetime.now(timezone.utc) - timedelta(hours=self.expiration_hours)
                
                cursor.execute('''
                    DELETE FROM upload_queue 
                    WHERE status = 'completed' AND timestamp_created < ?
                ''', (expiration_time.isoformat(),))
                
                completed_removed = cursor.rowcount
                
                # Remove uploads que excederam tentativas m√°ximas
                cursor.execute('''
                    DELETE FROM upload_queue 
                    WHERE status = 'pending' AND retry_count >= ?
                ''', (self.max_retry_attempts,))
                
                failed_removed = cursor.rowcount
                
                # Limpa logs de conectividade antigos
                cursor.execute('''
                    DELETE FROM connectivity_log 
                    WHERE timestamp < ?
                ''', (expiration_time.isoformat(),))
                
                logs_removed = cursor.rowcount
                
                conn.commit()
                
                if completed_removed > 0 or failed_removed > 0 or logs_removed > 0:
                    log_info(f"üßπ Limpeza conclu√≠da: {completed_removed} conclu√≠dos, "
                            f"{failed_removed} falhados, {logs_removed} logs removidos")
                
                self.stats['last_cleanup'] = datetime.now(timezone.utc).isoformat()
                
        except Exception as e:
            log_error(f"‚ùå Erro na limpeza de entradas antigas: {e}")
    
    def _insert_replay_record(self, upload: Dict, video_url: str) -> bool:
        """Insere registro replay ap√≥s upload bem-sucedido."""
        try:
            if not self.replay_manager:
                log_warning("‚ö†Ô∏è ReplayManager n√£o dispon√≠vel")
                return False
            
            camera_uuid = upload.get('camera_uuid')
            timestamp_video = upload.get('timestamp_video')
            bucket_path = upload.get('bucket_path')
            
            if not all([camera_uuid, timestamp_video, bucket_path]):
                log_warning("‚ö†Ô∏è Dados insuficientes para registro replay")
                return False
            
            # Gerar URL assinada se n√£o tiver
            if not video_url or not self._validar_url_completa(video_url):
                try:
                    from hierarchical_video_manager import HierarchicalVideoManager
                    video_manager = HierarchicalVideoManager()
                    if video_manager.conectar_supabase():
                        signed_url = video_manager._obter_url_assinada(bucket_path)
                        if signed_url and self._validar_url_completa(signed_url):
                            video_url = signed_url
                        else:
                            log_error("‚ùå Falha ao gerar URL assinada")
                            return False
                    else:
                        log_error("‚ùå Falha ao conectar video_manager")
                        return False
                except Exception as e:
                    log_error(f"‚ùå Erro ao gerar URL assinada: {e}")
                    return False
            
            # Converter timestamp para datetime
            from datetime import datetime, timezone
            try:
                timestamp_dt = datetime.fromisoformat(timestamp_video.replace('Z', '+00:00'))
            except:
                log_error("‚ùå Erro ao converter timestamp_video")
                return False
            
            # Inserir registro replay
            result = self.replay_manager.insert_replay_record(
                camera_id=camera_uuid,
                video_url=video_url,
                timestamp_video=timestamp_dt,
                bucket_path=bucket_path
            )
            
            if result.get('success'):
                log_success(f"‚úÖ Registro replay inserido: {upload.get('camera_id')}")
                return True
            else:
                log_error(f"‚ùå Falha no registro replay: {result.get('error')}")
                return False
                
        except Exception as e:
            log_error(f"‚ùå Erro na inser√ß√£o replay: {e}")
            return False
    
    def _mark_replay_inserted(self, upload_id: int):
        """Marca que o replay foi inserido para este upload."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute('''
                    UPDATE upload_queue 
                    SET replay_inserted = 1
                    WHERE id = ?
                ''', (upload_id,))
                
                conn.commit()
                log_debug(f"‚úÖ Replay marcado como inserido para upload ID: {upload_id}")
                
        except Exception as e:
            log_error(f"‚ùå Erro ao marcar replay como inserido: {e}")
    
    def _validar_url_completa(self, url):
        """Valida se URL √© completa e funcional."""
        if not url or not isinstance(url, str):
            return False
        url = url.strip()
        return (url.startswith('https://') and
                'supabase.co' in url and
                '?token=' in url and
                not url.startswith('supabase://bucket/'))
    
    def get_queue_status(self) -> Dict:
        """Retorna status atual da fila de uploads."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Contadores por status
                cursor.execute('''
                    SELECT status, COUNT(*) as count 
                    FROM upload_queue 
                    GROUP BY status
                ''')
                
                status_counts = dict(cursor.fetchall())
                
                # Tamanho total da fila
                cursor.execute('SELECT COUNT(*) FROM upload_queue')
                total_queue_size = cursor.fetchone()[0]
                
                # Uploads recentes (√∫ltimas 24h)
                recent_time = datetime.now(timezone.utc) - timedelta(hours=24)
                cursor.execute('''
                    SELECT COUNT(*) FROM upload_queue 
                    WHERE timestamp_created > ?
                ''', (recent_time.isoformat(),))
                
                recent_uploads = cursor.fetchone()[0]
                
                return {
                    'queue_size': total_queue_size,
                    'pending': status_counts.get('pending', 0),
                    'completed': status_counts.get('completed', 0),
                    'failed': status_counts.get('failed', 0),
                    'recent_uploads_24h': recent_uploads,
                    'is_monitoring': self._running,
                    'stats': self.stats.copy()
                }
                
        except Exception as e:
            log_error(f"‚ùå Erro ao obter status da fila: {e}")
            return {
                'queue_size': 0,
                'pending': 0,
                'completed': 0,
                'failed': 0,
                'recent_uploads_24h': 0,
                'is_monitoring': self._running,
                'stats': self.stats.copy()
            }
    
    def force_process_queue(self) -> Dict:
        """For√ßa o processamento da fila de uploads (para testes/debug)."""
        log_info("üîÑ For√ßando processamento da fila de uploads")
        
        if not self._check_connectivity():
            return {'success': False, 'error': 'Sem conectividade'}
        
        self._process_upload_queue()
        
        return {
            'success': True,
            'queue_status': self.get_queue_status()
        }


# Inst√¢ncia global para uso em outros m√≥dulos
_global_upload_manager = None

def get_upload_manager() -> OfflineUploadManager:
    """Retorna inst√¢ncia global do OfflineUploadManager."""
    global _global_upload_manager
    
    if _global_upload_manager is None:
        _global_upload_manager = OfflineUploadManager()
        _global_upload_manager.start_monitoring()
    
    return _global_upload_manager


if __name__ == "__main__":
    # Teste b√°sico
    manager = OfflineUploadManager()
    
    print("Status da fila:")
    print(json.dumps(manager.get_queue_status(), indent=2))
    
    # Inicia monitoramento
    manager.start_monitoring()
    
    try:
        # Mant√©m rodando por 60 segundos para teste
        time.sleep(60)
    except KeyboardInterrupt:
        print("\nParando monitoramento...")
    finally:
        manager.stop_monitoring()